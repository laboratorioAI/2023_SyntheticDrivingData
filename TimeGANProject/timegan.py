'''
Author: Diego Tamayo
Based on Time-series Generative Adversarial Networks (TimeGAN) Codebase.
Reference: Jinsung Yoon, Daniel Jarrett, Mihaela van der Schaar,
"Time-series Generative Adversarial Networks," 
Neural Information Processing Systems (NeurIPS), 2019.
'''

import tensorflow as tf
import numpy as np
from utils import extract_time, rnn_cell, random_generator, batch_generator
import time


def timegan (ori_data, parameters):
    """Use original data as training set to generate synthetic data (time-series)
    Args:
    - ori_data: original time-series data
    - parameters: TimeGAN network parameters
    Returns:
    - generated_data: generated time-series data
    """

    # Initialization of the Graph.
    tf.compat.v1.reset_default_graph()

    # Basic Parameters.
    number_of_sequences, seq_len, dim = np.asarray(ori_data).shape
    print('- No. of sequences:                    ' + str(number_of_sequences))
    print('- No. of timesteps of each sequence:   ' + str(seq_len))
    print('- No. of features of each timestep:    ' + str(dim))

    # Maximum sequence length and each sequence length.
    ori_time, max_seq_len = extract_time(ori_data)
    print('\n')

    # Networks Parameters.
    hidden_dim   = parameters['hidden_dim']
    num_layers   = parameters['num_layer']
    iterations   = parameters['iterations']
    batch_size   = parameters['batch_size']
    module_name  = parameters['module'] 
    z_dim        = dim
    gamma        = 1

    # Tensor X, Z and T definitions.
    X = tf.compat.v1.placeholder(tf.float32, [None, max_seq_len, dim], name = "myinput_x")
    Z = tf.compat.v1.placeholder(tf.float32, [None, max_seq_len, z_dim], name = "myinput_z")
    T = tf.compat.v1.placeholder(tf.int32,   [None], name = "myinput_t")

    # TimeGAN networks definition.
    def embedder (X, T):
        """Embedding network between original feature space to latent space.
        Args:
        - X: input time-series features
        - T: input time information
        Returns:
        - H: embeddings
        """
        with tf.compat.v1.variable_scope("embedder", reuse = tf.compat.v1.AUTO_REUSE):
            e_cell = tf.nn.rnn_cell.MultiRNNCell([rnn_cell(module_name, hidden_dim) for _ in range(num_layers)])
            e_outputs, e_last_states = tf.nn.dynamic_rnn(e_cell, X, dtype=tf.float32, sequence_length = T)
            H = tf.contrib.layers.fully_connected(e_outputs, hidden_dim, activation_fn=tf.nn.sigmoid)
        return H
      
    def recovery (H, T):   
        """Recovery network from latent space to original space.
        Args:
        - H: latent representation
        - T: input time information
        Returns:
        - X_tilde: recovered data
        """     
        with tf.compat.v1.variable_scope("recovery", reuse = tf.compat.v1.AUTO_REUSE):
            r_cell = tf.nn.rnn_cell.MultiRNNCell([rnn_cell(module_name, hidden_dim) for _ in range(num_layers)])
            r_outputs, r_last_states = tf.nn.dynamic_rnn(r_cell, H, dtype=tf.float32, sequence_length = T)
            X_tilde = tf.contrib.layers.fully_connected(r_outputs, dim, activation_fn=tf.nn.sigmoid) 
        return X_tilde
    
    def generator (Z, T):  
        """Generator function: Generate time-series data in latent space.
        Args:
        - Z: random variables
        - T: input time information
        Returns:
        - E: generated embedding
        """        
        with tf.compat.v1.variable_scope("generator", reuse = tf.compat.v1.AUTO_REUSE):
            e_cell = tf.nn.rnn_cell.MultiRNNCell([rnn_cell(module_name, hidden_dim) for _ in range(num_layers)])
            e_outputs, e_last_states = tf.nn.dynamic_rnn(e_cell, Z, dtype=tf.float32, sequence_length = T)
            E = tf.contrib.layers.fully_connected(e_outputs, hidden_dim, activation_fn=tf.nn.sigmoid)     
        return E
        
    def supervisor (H, T): 
        """Generate next sequence using the previous sequence. Dimension: (128, 24, 80)
        Args:
        - H: latent representation
        - T: input time information
        Returns:
        - S: generated sequence based on the latent representations generated by the generator
        """          
        with tf.compat.v1.variable_scope("supervisor", reuse = tf.compat.v1.AUTO_REUSE):
            e_cell = tf.nn.rnn_cell.MultiRNNCell([rnn_cell(module_name, hidden_dim) for _ in range(num_layers-1)])
            e_outputs, e_last_states = tf.nn.dynamic_rnn(e_cell, H, dtype=tf.float32, sequence_length = T)
            S = tf.contrib.layers.fully_connected(e_outputs, hidden_dim, activation_fn=tf.nn.sigmoid)     
        return S
          
    def discriminator (H, T):
        """Discriminate the original and synthetic time-series data.
        Args:
        - H: latent representation
        - T: input time information
        Returns:
        - Y_hat: classification results between original and synthetic time-series
        """        
        with tf.compat.v1.variable_scope("discriminator", reuse = tf.compat.v1.AUTO_REUSE):
            d_cell = tf.nn.rnn_cell.MultiRNNCell([rnn_cell(module_name, hidden_dim) for _ in range(num_layers)])
            d_outputs, d_last_states = tf.nn.dynamic_rnn(d_cell, H, dtype=tf.float32, sequence_length = T)
            Y_hat = tf.contrib.layers.fully_connected(d_outputs, 1, activation_fn=None) 
        return Y_hat


    # Embedding, Supervisor and Recovery networks.       X >> H >> X_tilde
    #                                                           >> H_supervised
    #
    H            = embedder(X, T)       # dim        -> hidden_dim  Generate latent sequence H based on original sequence X.
    H_supervised = supervisor(H, T)     # hidden_dim -> hidden_dim  Generate next latent secquence based on latent sequence H.
    X_tilde      = recovery(H, T)       # hidden_dim -> dim         Maps latent sequence H to original space.

    # Generator and Recovery networks.                   Z >> HZ >> HZ_supervised
    #
    HZ            = generator(Z, T)                 # dim        -> hidden_dim  Generate latent aleatory sequence HZ.
    HZ_supervised = supervisor(HZ, T)               # hidden_dim -> hidden_dim  Generate next latent sequence based on latent sequence HZ.
    XZ_tilde      = recovery(HZ_supervised, T)      # hidden_dim -> dim         Maps latent sequence HZ_supervised to original space.

    # Discriminator.                                     H             >> Y_H
    #                                                    HZ            >> Y_HZ
    #                                                    HZ_supervised >> Y_HZ_supervised
    #
    Y_H             = discriminator(H, T)       # hidden_dim -> 1       Discriminate latent sequence H.
    Y_HZ            = discriminator(HZ, T)      # hidden_dim -> 1       Discriminate latent sequence HZ.
    Y_HZ_supervised = discriminator(HZ_supervised, T)  # hidden_dim -> 1       Discriminate latent sequence HZ_supervised.

    # Variables.
    e_vars = [v for v in tf.compat.v1.trainable_variables() if v.name.startswith('embedder')]
    r_vars = [v for v in tf.compat.v1.trainable_variables() if v.name.startswith('recovery')]
    g_vars = [v for v in tf.compat.v1.trainable_variables() if v.name.startswith('generator')]
    s_vars = [v for v in tf.compat.v1.trainable_variables() if v.name.startswith('supervisor')]
    d_vars = [v for v in tf.compat.v1.trainable_variables() if v.name.startswith('discriminator')]

    # Network names.
    variable_names = []
    for variable in tf.compat.v1.trainable_variables():
        variable_names.append(variable.name)

    # parameters of each network.
    total_parameters = 0
    current_network = variable_names[0].split('/')[0]

    print("\n--------------------------------------------------------------------------")
    print("--------------------- TIMEGAN NETWORKS DESCRIPTIONS ----------------------")
    print("--------------------------------------------------------------------------")
    print('\n-> MAIN NETWORK: ', current_network)
    print("--------------------------------------------------------------------------")

    for name in variable_names:
        if name.split('/')[0] != current_network :
            print('\n')
            current_network = name.split('/')[0]
            print('-> MAIN NETWORK:', name.split('/')[0])
            print("--------------------------------------------------------------------------")
        print('-> SECONDARY NETWORK:', name)
        for variable in tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.TRAINABLE_VARIABLES, name):
            shape = variable.get_shape()
            print("   - Size of the matrix: {}".format(shape))
            variable_parameters = 1
            for dim in shape:
                variable_parameters *= dim.value
            print("   - Total number of elements in a matrix: {}".format(variable_parameters))
            print("--------------------------------------------------------------------------")
            total_parameters += variable_parameters
    print("-> TOTAL NUMBER OF PARAMETERS: {}".format(total_parameters))
    print("--------------------------------------------------------------------------\n")

    # Losses.

    # Discriminator loss.
    D_loss_H   = tf.compat.v1.losses.sigmoid_cross_entropy(tf.ones_like(Y_H), Y_H)
    D_loss_HZ  = tf.compat.v1.losses.sigmoid_cross_entropy(tf.zeros_like(Y_HZ), Y_HZ)
    D_loss_HZ_supervised   = tf.compat.v1.losses.sigmoid_cross_entropy(tf.zeros_like(Y_HZ_supervised), Y_HZ_supervised)
    D_loss     = D_loss_H + D_loss_HZ * gamma + D_loss_HZ_supervised

    # Generator loss.
    # 1. Adversarial loss
    G_loss_U_HZ              = tf.compat.v1.losses.sigmoid_cross_entropy(tf.ones_like(Y_HZ), Y_HZ)
    G_loss_U_HZ_supervised   = tf.compat.v1.losses.sigmoid_cross_entropy(tf.ones_like(Y_HZ_supervised), Y_HZ_supervised)
    # 2. Supervised loss.
    G_loss_S = tf.compat.v1.losses.mean_squared_error(H[:,1:,:], H_supervised[:, :-1, :])
    # 3. Two Momments.
    G_loss_V1 = tf.reduce_mean(tf.abs(tf.sqrt(tf.nn.moments(XZ_tilde,[0])[1] + 1e-6) - tf.sqrt(tf.nn.moments(X,[0])[1] + 1e-6)))
    G_loss_V2 = tf.reduce_mean(tf.abs(       (tf.nn.moments(XZ_tilde,[0])[0])       -         (tf.nn.moments(X,[0])[0])))
    G_loss_V = G_loss_V1 + G_loss_V2
    G_loss   = G_loss_U_HZ_supervised + gamma * G_loss_U_HZ + 100 * tf.sqrt(G_loss_S) + (100 * G_loss_V)

    # Embedder network loss.
    E_loss_T0 = tf.compat.v1.losses.mean_squared_error(X, X_tilde)
    E_loss0   = 10 * tf.sqrt(E_loss_T0)
    E_loss    = E_loss0  + (0.1 * G_loss_S)

    # Optimizers.
    E0_solver = tf.compat.v1.train.AdamOptimizer().minimize(E_loss0,  var_list = e_vars + r_vars)
    E_solver  = tf.compat.v1.train.AdamOptimizer().minimize(E_loss,   var_list = e_vars + r_vars)
    D_solver  = tf.compat.v1.train.AdamOptimizer().minimize(D_loss,   var_list = d_vars)
    G_solver  = tf.compat.v1.train.AdamOptimizer().minimize(G_loss,   var_list = g_vars + s_vars)
    GS_solver = tf.compat.v1.train.AdamOptimizer().minimize(G_loss_S, var_list = g_vars + s_vars)

    # TimeGAN training.

    # Initial training time.
    start_time = time.time()

    # >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
    # >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> PROCESSING START >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
    # >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

    sess = tf.compat.v1.Session()
    sess.run(tf.compat.v1.global_variables_initializer())

    # Embedding network training.
    print('\n>> Start Embedding Network Training...')

    for number_of_iterations in range(iterations):
        # Set mini-batch.
        X_mb, T_mb = batch_generator(ori_data, ori_time, batch_size)

        # Train embedder.
        _, step_e_loss = sess.run([E0_solver, E_loss_T0], feed_dict = {X: X_mb, T: T_mb})
        # H is calculated         = embedder(X, T)
        # X_tilde is calculated   = recovery(H, T)
        # E_loss_T0 is calculated = tf.losses.mean_squared_error(X, X_tilde)
        # E_loss0 is calculated   = 10 * tf.sqrt(E_loss_T0)
        # E0_solver is calculated = tf.train.AdamOptimizer().minimize(E_loss0, var_list = e_vars + r_vars)

        if number_of_iterations % 100 == 0:
            print('    step: '+ str(number_of_iterations) + '/' + str(iterations) + ', embedding loss: ' + str(np.round(np.sqrt(step_e_loss),4)) )
    print('\n-- Finish Embedding Network Training')

    # Training only with supervised loss.
    print('\n>> Start Training with Supervised Loss Only...')

    for number_of_iterations in range(iterations):
        # Set mini-batches
        X_mb, T_mb = batch_generator(ori_data, ori_time, batch_size)    
        Z_mb = random_generator(batch_size, z_dim, T_mb, max_seq_len)

        _, step_g_loss_s = sess.run([GS_solver, G_loss_S], feed_dict = {Z: Z_mb, X: X_mb, T: T_mb})

        if number_of_iterations % 100 == 0:
            print('    step: '+ str(number_of_iterations)  + '/' + str(iterations) +', supervised loss: ' + str(np.round(np.sqrt(step_g_loss_s),4)) )
    print('\n-- Finish Training with Supervised Loss Only')

    # Joint Training.
    print('\n>> Start Joint Training...')

    for number_of_iterations in range(iterations):
        # Generator training (twice more than discriminator training)
        for kk in range(2):
            # Set mini-batches
            X_mb, T_mb = batch_generator(ori_data, ori_time, batch_size)
            Z_mb = random_generator(batch_size, z_dim, T_mb, max_seq_len)
            # Train generator
            _, step_g_loss_u, step_g_loss_s, step_g_loss_v = sess.run([G_solver, G_loss_U_HZ_supervised, G_loss_S, G_loss_V], feed_dict={Z: Z_mb, X: X_mb, T: T_mb})
            # Train embedder
            _, step_e_loss_t0 = sess.run([E_solver, E_loss_T0], feed_dict = {Z: Z_mb, X: X_mb, T: T_mb})
           
        # Discriminator training        
        # Set mini-batches
        X_mb, T_mb = batch_generator(ori_data, ori_time, batch_size)
        Z_mb = random_generator(batch_size, z_dim, T_mb, max_seq_len) # array con 32 arrays de 24 secuencias de 8 dimensiones cada una.

        # Check discriminator loss before updating
        check_d_loss = sess.run(D_loss, feed_dict = {X: X_mb, T: T_mb, Z: Z_mb})
        # Train discriminator (only when the discriminator does not work well)
        if (check_d_loss > 0.15):        
            _, step_d_loss = sess.run([D_solver, D_loss], feed_dict = {X: X_mb, T: T_mb, Z: Z_mb})

        # Print multiple checkpoints
        if number_of_iterations % 100 == 0:
            print('    step: '    + str(number_of_iterations) + '/' + str(iterations) +
                  ', d_loss: '    + str(np.round(step_d_loss, 4)) +
                  ', g_loss_u: '  + str(np.round(step_g_loss_u, 4)) +
                  ', g_loss_s: '  + str(np.round(np.sqrt(step_g_loss_s), 4)) +
                  ', g_loss_v: '  + str(np.round(step_g_loss_v, 4)) +
                  ', e_loss_t0: ' + str(np.round(np.sqrt(step_e_loss_t0), 4)))

    print('\n-- Finish Joint Training')

    # Cálculo del tiempo en horas empleado en el entrenamiento.
    finish_time = time.time()
    total_horas = (finish_time - start_time)/3600
    print('\n*** Time elapsed in hours for total training:', total_horas, 'hours')

    # Synthetic data generation.
    Z_mb = random_generator(number_of_sequences, z_dim, ori_time, max_seq_len)

    generated_data_curr = sess.run(XZ_tilde, feed_dict={Z: Z_mb, T: ori_time})
    print('\n-> Generated data dataset shape: ', np.shape(generated_data_curr))

    generated_data = list()

    for i in range(number_of_sequences):
        temp = generated_data_curr[i,:ori_time[i],:]
        generated_data.append(temp)

    return generated_data